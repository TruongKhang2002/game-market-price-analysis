# ==========================================
# SHARED CONFIGURATION
# ==========================================
x-airflow-common: &airflow-common
  build: .
  # env_file sẽ tự động load các biến trong .env vào container
  env_file: .env
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    # Kết nối DB dùng biến từ .env
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres-airflow/${POSTGRES_AIRFLOW_DB}
    JAVA_HOME: /usr/lib/jvm/java-17-openjdk-amd64
  volumes:
    - ./dags:/opt/airflow/dags
    - ./scripts:/opt/airflow/scripts
    - ./jars:/opt/airflow/jars-custom
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins

services:
  # ==========================================
  # 1. STORAGE LAYER
  # ==========================================
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "${MINIO_API_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  postgres-dw:
    image: postgres:${POSTGRES_VERSION}
    container_name: postgres-dw
    environment:
      POSTGRES_USER: ${POSTGRES_DW_USER}
      POSTGRES_PASSWORD: ${POSTGRES_DW_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DW_DB}
    ports:
      - "${POSTGRES_DW_PORT}:5432"
    volumes:
      - postgres_dw_data:/var/lib/postgresql/data
    restart: always

  postgres-airflow:
    image: postgres:${POSTGRES_VERSION}
    container_name: postgres-airflow
    environment:
      POSTGRES_USER: ${POSTGRES_AIRFLOW_USER}
      POSTGRES_PASSWORD: ${POSTGRES_AIRFLOW_PASSWORD}
      POSTGRES_DB: ${POSTGRES_AIRFLOW_DB}
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_AIRFLOW_USER}"]
      interval: 10s
      retries: 5
    restart: always

  # ==========================================
  # 2. PROCESSING LAYER
  # ==========================================
  spark-master:
    image: apache/spark:${SPARK_IMAGE_TAG}
    container_name: spark-master
    user: root
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
    ports:
      - "${SPARK_MASTER_WEBUI_PORT}:8080"
      - "${SPARK_MASTER_PORT}:7077"
    volumes:
      - ./scripts:/opt/spark/scripts
      - ./jars:/opt/airflow/jars-custom

  spark-worker:
    image: apache/spark:${SPARK_IMAGE_TAG}
    container_name: spark-worker
    user: root
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_WORKER_MEMORY: ${SPARK_WORKER_MEMORY}
      SPARK_WORKER_CORES: ${SPARK_WORKER_CORES}
    ports:
      - "${SPARK_WORKER_WEBUI_PORT}:8081"
    volumes:
      - ./scripts:/opt/spark/scripts
      - ./jars:/opt/airflow/jars-custom
    depends_on:
      - spark-master

  # ==========================================
  # 3. ORCHESTRATION LAYER
  # ==========================================
  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    user: "0:0"
    entrypoint:
      - /bin/bash
      - -c
      - |
        echo "=== [INIT] STARTING SETUP ==="
        
        echo "--- Setting up permissions ---"
        mkdir -p /opt/airflow/{logs,dags,plugins}
        chown -R airflow:root /opt/airflow/{logs,dags,plugins}
        chmod -R 777 /opt/airflow/{logs,dags,plugins}

        export PATH=/home/airflow/.local/bin:$$PATH
        
        echo "--- Waiting for Postgres ---"
        until nc -z postgres-airflow 5432; do
          echo "Postgres is unavailable - sleeping"
          sleep 2
        done
        
        echo "--- Running DB Migrate ---"
        airflow db migrate

        echo "--- Creating Admin User ---"
        # Sử dụng biến môi trường từ .env để tạo user
        airflow users create \
          --username $$AIRFLOW_ADMIN_USER \
          --password $$AIRFLOW_ADMIN_PASSWORD \
          --firstname Airflow \
          --lastname Admin \
          --role Admin \
          --email $$AIRFLOW_ADMIN_EMAIL || true
          
        echo "=== [INIT] COMPLETED SUCCESSFULLY ==="
    depends_on:
      postgres-airflow:
        condition: service_healthy

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    user: "0:0"
    command: webserver
    ports:
      - "${AIRFLOW_WEBSERVER_PORT}:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 30s
      retries: 5
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    user: "0:0"
    command: scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully

volumes:
  minio_data:
  postgres_dw_data:
  postgres_airflow_data:
